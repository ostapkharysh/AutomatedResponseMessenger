{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/ukrainian_reviews.csv', sep='|')\n",
    "del data['opinion_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opinion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>хороше місце щоб провести вечір, кальяни смачн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>взуттям задоволена. беру не перший раз.  мінус...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>відмінний магазин та чемний продавець, єдиним ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>замовляв дві штуки, а відправили 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>замовляю вже втретє в цьому магазині і планую ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        opinion_text\n",
       "0  хороше місце щоб провести вечір, кальяни смачн...\n",
       "1  взуттям задоволена. беру не перший раз.  мінус...\n",
       "2  відмінний магазин та чемний продавець, єдиним ...\n",
       "3                 замовляв дві штуки, а відправили 1\n",
       "4  замовляю вже втретє в цьому магазині і планую ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/data.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = []\n",
    "    for line in gzip.open(path, 'rb'):\n",
    "        df.append(eval(line))\n",
    "    return pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data('data/qa_Appliances.json.gz')\n",
    "df = df['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/qa_data.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data_file = 'data/data.txt'\n",
    "training_data_file = 'data/qa_data.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(sentence):\n",
    "    return sentence.translate(str.maketrans('','', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(dictionary, key, value):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = []\n",
    "    dictionary[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2probabilitydict(given_list):\n",
    "    probability_dict = {}\n",
    "    given_list_length = len(given_list)\n",
    "    for item in given_list:\n",
    "        probability_dict[item] = probability_dict.get(item, 0) + 1\n",
    "    for key, value in probability_dict.items():\n",
    "        probability_dict[key] = value / given_list_length\n",
    "    return probability_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_word = {}\n",
    "second_word = {}\n",
    "transitions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a Markov model based on the data in training_data_file\n",
    "def train_markov_model():\n",
    "    for line in open(training_data_file, encoding='utf-8'):\n",
    "        tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "        tokens_length = len(tokens)\n",
    "        for i in range(tokens_length):\n",
    "            token = tokens[i]\n",
    "            if i == 0:\n",
    "                initial_word[token] = initial_word.get(token, 0) + 1\n",
    "            else:\n",
    "                prev_token = tokens[i - 1]\n",
    "                if i == tokens_length - 1:\n",
    "                    add2dict(transitions, (prev_token, token), 'END')\n",
    "                if i == 1:\n",
    "                    add2dict(second_word, prev_token, token)\n",
    "                else:\n",
    "                    prev_prev_token = tokens[i - 2]\n",
    "                    add2dict(transitions, (prev_prev_token, prev_token), token)\n",
    "    \n",
    "    # Normalize the distributions\n",
    "    initial_word_total = sum(initial_word.values())\n",
    "    for key, value in initial_word.items():\n",
    "        initial_word[key] = value / initial_word_total\n",
    "        \n",
    "    for prev_word, next_word_list in second_word.items():\n",
    "        second_word[prev_word] = list2probabilitydict(next_word_list)\n",
    "        \n",
    "    for word_pair, next_word_list in transitions.items():\n",
    "        transitions[word_pair] = list2probabilitydict(next_word_list)\n",
    "    \n",
    "    print('Training successful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training successful.\n"
     ]
    }
   ],
   "source": [
    "train_markov_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(dictionary):\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for key, value in dictionary.items():\n",
    "        cumulative += value\n",
    "        if p0 < cumulative:\n",
    "            return key\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sentences = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sample text\n",
    "def generate():\n",
    "    for i in range(number_of_sentences):\n",
    "        sentence = []\n",
    "        # Initial word\n",
    "        word0 = sample_word(initial_word)\n",
    "        sentence.append(word0)\n",
    "        # Second word\n",
    "        word1 = sample_word(second_word[word0])\n",
    "        sentence.append(word1)\n",
    "        # Subsequent words untill END\n",
    "        while True:\n",
    "            word2 = sample_word(transitions[(word0, word1)])\n",
    "            if word2 == 'END':\n",
    "                break\n",
    "            sentence.append(word2)\n",
    "            word0 = word1\n",
    "            word1 = word2\n",
    "        print(i, ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 i have cooked with it also hope this helpedi love this machine i would say id you want it to replace my filter in our water and use a weak bleachwater solution wipe all services that we love out parts we have done for both which units do u turn on small motor keeps a constant real time update on temp and a few months of quiet operation its beginning to get temperatures right it doesnt accumulate too much i always try to repair or replace parts before we replaced it once and didnt replace the entire laminate material is placed on top of the biggest that will listen how much grease you generate its safe to drink with use of original mounting holes are different it does yes see httpwwwappliancepartsproscomgerackasmlowerwd28x10284ap4980665html i bought them for connecting the water supply line on httpwwwappliancepartsproscomwhirlpoolwaterfilterhousing2186443ap3085317html takes you to use and still like new amazon makes a converter on the back of the paneldrum light fresh hold steam for stainsthe fifth one down is if the new one has the non duct kit for the price is much less floaties from ice cubes take a photo of your smoker to increase or humidity i have one for you particular model any more lg product because of the job they hired a musician not an exact fit in fridge the the aos 7144 httpwwwairoswissnetinfoultrasonics7144aspx\n",
      "1 this product if yours looks similar to lt700p both may work but that is about 1 year warranty\n",
      "2 there are two wheels on it i dont think it does a good connection with your colored cloths by how much cubic feet dimension inner more so the cabinets\n",
      "3 there are youtube videos if the replacementsubstitute part is identical to the outside you would still need the wh01x10302 belt\n",
      "4 sorry i dont know about other brands it replaces 5231ja2002a for model 5231ja2002as check your old filter and see which icemaker part matches your all set\n",
      "5 this heating element when its running from where it works perfectly\n",
      "6 it does\n",
      "7 the only suggestion i may pack some heat resistant ceramic wool in the tray it will come out cleaner which you interlock by stacking one on each channel which will be better i highly recommend a speed queen this is a hands on machine had to be cast iron skillet it does not\n",
      "8 i did not use mine the less satisfied i am not the heavier actual metal ducts you have to pay almost half the cost and when she cans she puts in the bleach everywhere in the garage for 13 years works great better than the rubbish whirlpool put in the accompanying user manual\n",
      "9 yes i can easily accommodate eight normal dinnersized plates no problem putting this one was mailed to you try it out yet we have listed it comes on at the layout of the 30 is fine as long as you can go rancid the the dispenser and then the unicoupler connects to the water line is a common heating coil as the distance to the options i use it and where the voltage being pulled wiring may not be difficult to get a smell to it then the inner edge that rests on pads i hope it helps you out\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
